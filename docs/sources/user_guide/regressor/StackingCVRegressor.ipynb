{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# StackingCVRegressor\n",
    "\n",
    "An ensemble-learning meta-regressor for stacking using out-of-fold predictions to prepare the inputs for the level-2 regressor to prevent overfitting.\n",
    "\n",
    "\n",
    "# Algorithm\n",
    "\n",
    "Stacking is an ensemble learning technique to combine multiple regression models via a meta-regressor. The StackingCVRegressor extends the standard stacking algorithm (implemented as StackingRegressor) using out-of-fold predictions to prepare the input data for the level-2 classifier.\n",
    "\n",
    "In the standard stacking procedure, the first-level regressors are fit to the same training set that is used prepare the inputs for the second-level regressor, which may lead to overfitting. The StackingCVRegressor, however, uses the concept of out-of-fold predictions: the dataset is split into k folds, and in k successive rounds, k-1 folds are used to fit the first level regressor; in each round, the first-level regressors are then applied to the remaining 1 subset that was not used for model fitting in each iteration. The resulting predictions are then stacked and provided -- as input data -- to the second-level regressor. After the training of the StackingCVRegressor, the first-level regressors are fit to the entire dataset for optimal training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Boston housing data predictions\n",
    "\n",
    "In this example we evaluate some basic prediction models on the boston housing dataset and see how score is affected by combining the models with StackingCVRegressor. See below, script output demonstrates that the stacked model performs the best, slightly better than the best single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold cross validation scores:\n",
      "\n",
      "Score: 0.45 (+/- 0.29) [SVM]\n",
      "Score: 0.43 (+/- 0.14) [Lasso]\n",
      "Score: 0.57 (+/- 0.21) [Random Forest]\n",
      "Score: 0.58 (+/- 0.25) [StackingClassifier]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "svr = SVR(kernel='linear')\n",
    "lasso = Lasso()\n",
    "rf = RandomForestRegressor(n_estimators=5)\n",
    "\n",
    "stack = StackingCVRegressor(regressors=(svr, lasso, rf), meta_regressor=lasso)\n",
    "\n",
    "print('5-fold cross validation scores:\\n')\n",
    "\n",
    "for clf, label in zip([svr, lasso, rf, stack], ['SVM', 'Lasso', 'Random Forest', 'StackingClassifier']):\n",
    "    scores = cross_val_score(clf, X, y, cv=5)\n",
    "    print(\"Score: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Example 2: GridSearchCV with stacking\n",
    "\n",
    "In this second example we demonstrate how StackingCVRegressor works in combination with GridSearchCV. The stack still allows tuning hyper parameters of the base and meta models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.674269 using {'ridge__alpha': 0.35, 'lasso__alpha': 1.2}\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "ridge = Ridge()\n",
    "lasso = Lasso()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "stack = StackingCVRegressor(regressors=(lasso, ridge), meta_regressor=rf, use_features_in_secondary=True)\n",
    "\n",
    "params = {'lasso__alpha': [0.1, 1.0, 10.0],\n",
    "          'ridge__alpha': [0.1, 1.0, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=stack, \n",
    "    param_grid={\n",
    "        'lasso__alpha': [x/5.0 for x in range(1,10)],\n",
    "        'ridge__alpha': [x/20.0 for x in range(1,10)]\n",
    "    }, \n",
    "    cv=5,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
